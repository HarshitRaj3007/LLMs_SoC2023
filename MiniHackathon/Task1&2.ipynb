{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./train.csv\").dropna()\n",
    "test_data = pd.read_csv(\"./test.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "6             7         0       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "6       0     17463  51.8625   E46        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>455.366120</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>1.191257</td>\n",
       "      <td>35.674426</td>\n",
       "      <td>0.464481</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>78.682469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>247.052476</td>\n",
       "      <td>0.470725</td>\n",
       "      <td>0.515187</td>\n",
       "      <td>15.643866</td>\n",
       "      <td>0.644159</td>\n",
       "      <td>0.754617</td>\n",
       "      <td>76.347843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>263.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>457.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>676.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   183.000000  183.000000  183.000000  183.000000  183.000000   \n",
       "mean    455.366120    0.672131    1.191257   35.674426    0.464481   \n",
       "std     247.052476    0.470725    0.515187   15.643866    0.644159   \n",
       "min       2.000000    0.000000    1.000000    0.920000    0.000000   \n",
       "25%     263.500000    0.000000    1.000000   24.000000    0.000000   \n",
       "50%     457.000000    1.000000    1.000000   36.000000    0.000000   \n",
       "75%     676.000000    1.000000    1.000000   47.500000    1.000000   \n",
       "max     890.000000    1.000000    3.000000   80.000000    3.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  183.000000  183.000000  \n",
       "mean     0.475410   78.682469  \n",
       "std      0.754617   76.347843  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000   29.700000  \n",
       "50%      0.000000   57.000000  \n",
       "75%      1.000000   90.000000  \n",
       "max      4.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([38.0000, 35.0000, 54.0000,  4.0000, 58.0000, 34.0000, 28.0000, 19.0000,\n",
       "        49.0000, 65.0000, 45.0000, 29.0000, 25.0000, 23.0000, 46.0000, 71.0000,\n",
       "        23.0000, 21.0000, 47.0000, 24.0000, 32.5000, 54.0000, 19.0000, 37.0000,\n",
       "        24.0000, 36.5000, 22.0000, 61.0000, 56.0000, 50.0000,  1.0000,  3.0000,\n",
       "        44.0000, 58.0000,  2.0000, 40.0000, 31.0000, 32.0000, 38.0000, 35.0000,\n",
       "        44.0000, 37.0000, 29.0000, 62.0000, 30.0000, 52.0000, 40.0000, 58.0000,\n",
       "        35.0000, 37.0000, 63.0000, 19.0000, 36.0000,  2.0000, 50.0000,  0.9200,\n",
       "        17.0000, 30.0000, 24.0000, 18.0000, 31.0000, 40.0000, 36.0000, 36.0000,\n",
       "        16.0000, 45.5000, 38.0000, 29.0000, 41.0000, 45.0000,  2.0000, 24.0000,\n",
       "        24.0000, 22.0000, 60.0000, 24.0000, 25.0000, 27.0000, 36.0000, 23.0000,\n",
       "        24.0000, 33.0000, 32.0000, 28.0000, 50.0000, 14.0000, 64.0000,  4.0000,\n",
       "        52.0000, 30.0000, 49.0000, 65.0000, 48.0000, 47.0000, 23.0000, 25.0000,\n",
       "        35.0000, 58.0000, 55.0000, 54.0000, 25.0000, 16.0000, 18.0000, 36.0000,\n",
       "        47.0000, 34.0000, 30.0000, 44.0000, 45.0000, 22.0000, 36.0000, 50.0000,\n",
       "        17.0000, 48.0000, 39.0000, 53.0000, 36.0000, 39.0000, 39.0000, 36.0000,\n",
       "        18.0000, 60.0000, 52.0000, 49.0000, 40.0000,  4.0000, 42.0000, 61.0000,\n",
       "        21.0000, 80.0000, 32.0000, 24.0000, 48.0000, 56.0000, 58.0000, 47.0000,\n",
       "        31.0000, 36.0000, 27.0000, 15.0000, 31.0000, 49.0000, 42.0000, 18.0000,\n",
       "        35.0000, 42.0000, 24.0000, 48.0000, 19.0000, 38.0000, 27.0000, 27.0000,\n",
       "        29.0000, 35.0000, 36.0000, 21.0000, 70.0000, 19.0000,  6.0000, 33.0000,\n",
       "        36.0000, 51.0000, 57.0000, 43.0000, 17.0000, 29.0000, 46.0000, 49.0000,\n",
       "        11.0000, 39.0000, 33.0000, 52.0000, 27.0000, 39.0000, 16.0000, 51.0000,\n",
       "        48.0000, 31.0000, 47.0000, 33.0000, 56.0000, 19.0000, 26.0000],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(train_data['Age'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.tensor(train_data['Age'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 12)\n",
      "(87, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows = 183\n",
      "No of unique:\n",
      "\n",
      "PassengerId = (183,)\n",
      "Survived = (2,)\n",
      "Pclass = (3,)\n",
      "Name = (183,)\n",
      "Sex = (2,)\n",
      "Age = (63,)\n",
      "SibSp = (4,)\n",
      "Parch = (4,)\n",
      "Ticket = (127,)\n",
      "Fare = (93,)\n",
      "Cabin = (133,)\n",
      "Embarked = (3,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total rows = {train_data.shape[0]}\")\n",
    "print(\"No of unique:\")\n",
    "print()\n",
    "for column in train_data.columns:\n",
    "\tprint(f\"{column} = {train_data[column].unique().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "6             7         0       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "\n",
       "                                                 Name  Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    1  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut    0   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth    0  58.0      0   \n",
       "\n",
       "    Parch  Ticket     Fare  Cabin  Embarked  \n",
       "1       0       0  71.2833      0         0  \n",
       "3       0       1  53.1000      1         1  \n",
       "6       0       2  51.8625      2         1  \n",
       "10      1       3  16.7000      3         1  \n",
       "11      0       4  26.5500      4         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexdict = {}\n",
    "ticketdict = {}\n",
    "cabindict = {}\n",
    "embarkeddict = {}\n",
    "\n",
    "for i,item in enumerate(train_data['Sex'].unique()):\n",
    "    sexdict[item] = i\n",
    "for i,item in enumerate(train_data['Ticket'].unique()):\n",
    "    ticketdict[item] = i\n",
    "for i,item in enumerate(train_data['Cabin'].unique()):\n",
    "    cabindict[item] = i\n",
    "for i,item in enumerate(train_data['Embarked'].unique()):\n",
    "    embarkeddict[item] = i\n",
    "train_data['Sex'] = train_data['Sex'].replace(sexdict)\n",
    "train_data['Ticket'] = train_data['Ticket'].replace(ticketdict)\n",
    "train_data['Cabin'] = train_data['Cabin'].replace(cabindict)\n",
    "train_data['Embarked'] = train_data['Embarked'].replace(embarkeddict)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0, 'S': 1, 'Q': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarkeddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.0000,   0.0000,  38.0000,  ...,  71.2833,   0.0000,   0.0000],\n",
       "        [  1.0000,   0.0000,  35.0000,  ...,  53.1000,   1.0000,   1.0000],\n",
       "        [  1.0000,   1.0000,  54.0000,  ...,  51.8625,   2.0000,   1.0000],\n",
       "        ...,\n",
       "        [  1.0000,   0.0000,  56.0000,  ...,  83.1583, 130.0000,   0.0000],\n",
       "        [  1.0000,   0.0000,  19.0000,  ...,  30.0000, 131.0000,   1.0000],\n",
       "        [  1.0000,   1.0000,  26.0000,  ...,  30.0000, 132.0000,   0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(train_data[['Pclass','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Val Split\n",
    "# mask = np.random.choice([0,1],size=len(train_data),p=[0.3,0.7])\n",
    "# print(mask.sum()/len(train_data))\n",
    "# train_df = train_data[mask]\n",
    "# val_df = train_data[~mask]\n",
    "# print(len(train_df))\n",
    "# print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "37\n",
      "183\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Duff Gordon, Lady. (Lucille Christiana Sutherl...</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Harper, Mr. Henry Sleeper</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Spedden, Mrs. Frederic Oakley (Margaretta Corn...</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>610</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Shutes, Miss. Elizabeth W</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>153.4625</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Thayer, Mrs. John Borland (Marian Longstreth M...</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>McGough, Mr. James Robert</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bissette, Miss. Amelia</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>135.6333</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>858</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Daly, Mr. Peter Denis</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "23            24         1       1   \n",
       "556          557         1       1   \n",
       "645          646         1       1   \n",
       "319          320         1       1   \n",
       "21            22         1       2   \n",
       "..           ...       ...     ...   \n",
       "609          610         1       1   \n",
       "581          582         1       1   \n",
       "512          513         1       1   \n",
       "269          270         1       1   \n",
       "857          858         1       1   \n",
       "\n",
       "                                                  Name  Sex   Age  SibSp  \\\n",
       "23                        Sloper, Mr. William Thompson    1  28.0      0   \n",
       "556  Duff Gordon, Lady. (Lucille Christiana Sutherl...    0  48.0      1   \n",
       "645                          Harper, Mr. Henry Sleeper    1  48.0      1   \n",
       "319  Spedden, Mrs. Frederic Oakley (Margaretta Corn...    0  40.0      1   \n",
       "21                               Beesley, Mr. Lawrence    1  34.0      0   \n",
       "..                                                 ...  ...   ...    ...   \n",
       "609                          Shutes, Miss. Elizabeth W    0  40.0      0   \n",
       "581  Thayer, Mrs. John Borland (Marian Longstreth M...    0  39.0      1   \n",
       "512                          McGough, Mr. James Robert    1  36.0      0   \n",
       "269                             Bissette, Miss. Amelia    0  35.0      0   \n",
       "857                             Daly, Mr. Peter Denis     1  51.0      0   \n",
       "\n",
       "     Parch  Ticket      Fare  Cabin  Embarked  \n",
       "23       0       6   35.5000      6         1  \n",
       "556      0      88   39.6000     87         0  \n",
       "645      0       8   76.7292      8         0  \n",
       "319      1      53  134.5000     52         0  \n",
       "21       0       5   13.0000      5         1  \n",
       "..     ...     ...       ...    ...       ...  \n",
       "609      0      41  153.4625     40         1  \n",
       "581      1      87  110.8833     89         0  \n",
       "512      0      79   26.2875     79         1  \n",
       "269      0      42  135.6333     41         1  \n",
       "857      0     121   26.5500    128         1  \n",
       "\n",
       "[146 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_data.sample(frac=0.8)\n",
    "val_df = train_data.drop(train_df.index)\n",
    "print(len(train_df))\n",
    "print(len(val_df))\n",
    "print(len(train_data))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, df):\n",
    "        # self.x = torch.tensor(df[['Pclass','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']].values,dtype=float)\n",
    "        self.x = torch.tensor(df[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']].values,dtype=float)\n",
    "        self.y = torch.tensor(df['Survived'].values,dtype=int)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,val_ds = Dataset(train_df),Dataset(val_df)\n",
    "assert len(train_ds)==len(train_df)\n",
    "assert len(val_ds)==len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 7])\n",
      "torch.Size([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.0000,   1.0000,  28.0000,   0.0000,   0.0000,  35.5000,   1.0000],\n",
       "         [  1.0000,   0.0000,  48.0000,   1.0000,   0.0000,  39.6000,   0.0000],\n",
       "         [  1.0000,   1.0000,  48.0000,   1.0000,   0.0000,  76.7292,   0.0000],\n",
       "         [  1.0000,   0.0000,  40.0000,   1.0000,   1.0000, 134.5000,   0.0000],\n",
       "         [  2.0000,   1.0000,  34.0000,   0.0000,   0.0000,  13.0000,   1.0000]],\n",
       "        dtype=torch.float64),\n",
       " tensor([1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "print(xb.shape)\n",
    "print(yb.shape)\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3229e+00,  6.3144e-01,  1.7547e-03,  1.7582e+00,  1.0038e-01],\n",
      "        [-9.1348e-01,  1.2946e+00, -1.2020e+00,  3.0924e-01,  2.2605e+00],\n",
      "        [ 5.3095e-01, -2.0284e-01, -9.8212e-01, -1.3727e+00, -1.2953e+00]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "tensor([1, 1, 0, 1, 1])\n",
      "tensor([[ 1.3229,  0.6314,  0.0000,  1.7582,  0.1004],\n",
      "        [-0.9135,  1.2946, -0.0000,  0.3092,  2.2605],\n",
      "        [ 0.5309, -0.2028, -0.0000, -1.3727, -1.2953]], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.4437, -0.2975,  0.0000, -2.2824, -1.6947],\n",
      "        [-1.2608,  1.8033,  0.0000,  4.4931,  4.8851],\n",
      "        [-0.3799, -0.4757,  0.0000, -1.8183, -0.8786],\n",
      "        [ 1.2622,  1.3621,  0.0000, -0.5783, -0.1397],\n",
      "        [ 4.5469,  0.7044,  0.0000,  1.4766, -3.0380],\n",
      "        [-1.5780,  2.2252,  0.0000,  1.3494,  4.2448],\n",
      "        [-1.1676,  1.2438,  0.0000, -0.8792,  1.9435],\n",
      "        [-0.0882, -1.5770,  0.0000, -0.7881, -1.7804],\n",
      "        [-2.3634,  0.9877,  0.0000, -0.4445,  3.0279],\n",
      "        [-0.1474,  1.5170,  0.0000,  0.6069,  1.8700]], dtype=torch.float64,\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(10,3,dtype=float).requires_grad_()\n",
    "w1 = torch.randn(3,5,dtype=float).requires_grad_()\n",
    "print(w1)\n",
    "drop = torch.tensor(np.random.choice([0,1], size=w1.shape[1], p=[0.2,0.8]))\n",
    "print(drop)\n",
    "res = torch.mul(w1,drop[None,:])\n",
    "print(res)\n",
    "print(inp@res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out, p, q):\n",
    "        super().__init__()\n",
    "        self.w1 = torch.randn(n_in,n_out,dtype=float).requires_grad_()\n",
    "        self.w2 = torch.randn(p,q,dtype=float).requires_grad_()\n",
    "        self.b = torch.zeros(n_out,dtype=float).requires_grad_()\n",
    "    def forward(self, inp):\n",
    "        return torch.einsum('ab,bc,pq->acpq', (inp, self.w1, self.w2)) + self.b[None,:,None,None]\n",
    "    def parameters(self):\n",
    "        return (self.w1,self.w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwd = Linear(9,5,2,3)\n",
    "# op = fwd(xb)\n",
    "# print(op.shape)\n",
    "# print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwd.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = torch.einsum('abcd->ab',op)\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def forward(self, inp):\n",
    "        if self.training: inp = inp.mul(torch.tensor(np.random.choice([0,1], size=inp.shape[1], p=[self.p,1-self.p])))\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(10,3,dtype=float).requires_grad_()\n",
    "test = Dropout(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4621, -0.2130, -0.2217],\n",
       "        [-0.0855, -1.5616, -1.0800],\n",
       "        [-0.0319,  0.9206,  0.5428],\n",
       "        [-0.2332,  1.2532,  0.1712],\n",
       "        [ 0.6363,  0.0658, -0.1382],\n",
       "        [ 0.0219,  0.5588, -0.1841],\n",
       "        [ 0.6196,  0.2055, -0.2327],\n",
       "        [ 0.9443,  1.4848,  0.5614],\n",
       "        [-0.2622,  0.6972,  0.6506],\n",
       "        [ 0.7634,  0.5284,  1.8743]], dtype=torch.float64,\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.train()\n",
    "test(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU_Sum(nn.Module):\n",
    "    def __init__(self,clamp=1):\n",
    "        super().__init__()\n",
    "        self.clamp = clamp\n",
    "    def forward(self,inp):\n",
    "        if self.clamp:\n",
    "            # return torch.einsum('abcd->ab',inp).clamp(min=0)/(inp.shape[2]*inp.shape[3])\n",
    "            # return torch.einsum('abcd->ab',inp).clamp(min=0)\n",
    "            return torch.mean(inp,dim=[2,3]).clamp(min=0)\n",
    "        else:\n",
    "            # return torch.einsum('abcd->ab',inp)/(inp.shape[2]*inp.shape[3])\n",
    "            # return torch.einsum('abcd->ab',inp)\n",
    "            return torch.mean(inp,dim=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actfn = ReLU_Sum()\n",
    "# temp = actfn(op)\n",
    "# temp,temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_in = 9\n",
    "# nh = 15\n",
    "# n_out = 1\n",
    "# p = 5\n",
    "# q = 5\n",
    "# xb1 = xb\n",
    "# layers = [Linear(n_in,nh,p,q),ReLU_Sum(),Linear(nh,n_out,p,q),ReLU_Sum(0)]\n",
    "# for l in layers: xb1 = l(xb1)\n",
    "# print(xb.shape)\n",
    "# print(yb[:,None].shape)\n",
    "# F.mse_loss(xb,yb[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        # self._modules = {}\n",
    "        # self.layers = nn.ModuleList([Linear(n_in,nh,p,q),ReLU_Sum(),Linear(nh,n_out,p,q),ReLU_Sum(0)])\n",
    "        self.layers = layers\n",
    "        # self.l1 = Linear(n_in,nh,p,q)\n",
    "        # self.r1 = ReLU_Sum()\n",
    "        # self.l2 = Linear(nh,n_out,p,q)\n",
    "        # self.r2 = ReLU_Sum(0)\n",
    "\n",
    "    # def __setattr__(self,k,v):\n",
    "    #     if not k.startswith(\"_\"): self._modules[k] = v\n",
    "    #     super().__setattr__(k,v)\n",
    "\n",
    "    # def __repr__(self): return f'{self._modules}'\n",
    "\n",
    "    def parameters(self):\n",
    "        for l in self.layers: yield from l.parameters()\n",
    "        # for l in self._modules.values(): yield from l.parameters()\n",
    "        \n",
    "    # def __call__(self, x, targ):\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        # for l in self._modules.values(): x = l(x)\n",
    "        # return F.mse_loss(x,targ[:,None])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate(b):\n",
    "#     xs,ys = zip(*b)\n",
    "#     return torch.stack(xs),torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_samp = BatchSampler(RandomSampler(train_ds), 50, drop_last=False)\n",
    "# val_samp = BatchSampler(SequentialSampler(val_ds), 50, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "# val_dl = DataLoader(val_ds, batch_sampler=val_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "# val_dl = DataLoader(val_ds, sampler=val_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb,yb = next(iter(val_dl))\n",
    "# xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(9,15,1,5,5)\n",
    "# loss = model(xb,yb)\n",
    "# print(loss)\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l0 = model.layers[0]\n",
    "# print(l0.b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(9,15,2,5,5)\n",
    "# pred = model(train_ds.x)\n",
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func(pred,train_ds.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, targ): return (out.argmax(dim=1)==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy(pred, train_ds.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(loss, preds, yb):\n",
    "\tacc = accuracy(preds, yb)\n",
    "\tprint(f'{loss}, {acc}')\n",
    "\treturn acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb,yb = train_ds.x[:bs],train_ds.y[:bs]\n",
    "# preds = model(xb)\n",
    "# report(loss_func(preds, yb), preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.parameters())[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(p1,p2):\n",
    "    layers = nn.ModuleList([Linear(7,15,3,3),\n",
    "                   ReLU_Sum(),\n",
    "                   Dropout(p1),\n",
    "                   Linear(15,2,3,3),\n",
    "                   ReLU_Sum(0),\n",
    "                   Dropout(p2)])\n",
    "    model = Model(layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model= get_model()\n",
    "# loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = slice(0, 50)\n",
    "# xb,yb = train_ds.x[s],train_ds.y[s]\n",
    "# preds = model(xb)\n",
    "# loss = loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xb.shape,yb.shape)\n",
    "# print((preds[:,1]>preds[:,0]).float().mean())\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list(model.parameters())[0]\n",
    "# list(model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt.step()\n",
    "# list(model.parameters())[0]\n",
    "# # list(model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt.zero_grad()\n",
    "# list(model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.05\n",
    "# epochs = 100\n",
    "# bs = 100\n",
    "# n = len(train_ds)\n",
    "\n",
    "# model= get_model()\n",
    "# opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "# sch = optim.lr_scheduler.ExponentialLR(opt, 0.99)\n",
    "# loss_hist = []\n",
    "# valloss_hist = []\n",
    "# acc_hist = []\n",
    "# valacc_hist = []\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     for i in range(0, n, bs):\n",
    "#         s = slice(i, min(n,i+bs))\n",
    "#         xb,yb = train_ds.x[s],train_ds.y[s]\n",
    "#         preds = model(xb)\n",
    "#         loss = loss_func(preds, yb)\n",
    "#         loss_hist.append(loss.detach().numpy())\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         opt.zero_grad()\n",
    "#     sch.step()\n",
    "#     acc_hist.append(report(loss, preds, yb))\n",
    "#     if(epoch%5==0):\n",
    "#         print(\"VAL:\")\n",
    "#         with torch.no_grad():\n",
    "#             xb,yb = val_ds.x,val_ds.y\n",
    "#             preds = model(xb)\n",
    "#             loss = loss_func(preds, yb)\n",
    "#             valloss_hist.append(loss.detach().numpy())\n",
    "#             valacc_hist.append(report(loss, preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss_hist)\n",
    "# plt.plot(valloss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(acc_hist)\n",
    "# plt.plot(valacc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, sch, train_dl, valid_dl, verbose=False):\n",
    "    \n",
    "    loss_hist = []\n",
    "    valloss_hist = []\n",
    "    valacc_hist = []\n",
    "    # best_params = None\n",
    "    # best_acc = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        tot_loss,count = 0.,0\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            n = len(xb)\n",
    "            count += n\n",
    "            tot_loss += loss.item()*n\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        loss_hist.append(tot_loss/count)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc,count = 0.,0.,0\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(pred,yb).item()*n\n",
    "                tot_acc  += accuracy (pred,yb).item()*n\n",
    "        \n",
    "        acc = tot_acc/count\n",
    "        valloss_hist.append(tot_loss/count)\n",
    "        valacc_hist.append(tot_acc/count)\n",
    "        if verbose:\n",
    "            print(epoch, tot_loss/count, tot_acc/count)\n",
    "\n",
    "        # if(acc>best_acc):\n",
    "        #     best_acc = acc\n",
    "        #     best_params = model.parameters()\n",
    "        #     print(f\"New best model with acc = {acc}\")\n",
    "\n",
    "        sch.step()\n",
    "    # return (loss_hist,valloss_hist,valacc_hist,best_params,best_acc)\n",
    "    return (loss_hist,valloss_hist,valacc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, shuffle=False, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100\n",
    "train_dl,valid_dl = get_dls(train_ds, val_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(0.2,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 15])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([15, 2])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 108 ms, total: 1.24 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "epochs = 500\n",
    "opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-7)\n",
    "sch = optim.lr_scheduler.ExponentialLR(opt, 0.999)\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "%time lh,vlh,vah = fit(epochs, model, loss_func, opt, sch, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16b299190>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lh)\n",
    "plt.plot(vlh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16d18ded0>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best of n Val Acc\n",
    "def test_loop(p1,p2,epochs,n, plot5=False):\n",
    "    VA = []\n",
    "    for i in range(n):\n",
    "        model = get_model(p1,p2)\n",
    "        lr = 0.05\n",
    "        opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-7)\n",
    "        sch = optim.lr_scheduler.ExponentialLR(opt, 0.995)\n",
    "        _,_,val_acc = fit(epochs, model, loss_func, opt, sch, train_dl, valid_dl, verbose=False)\n",
    "        VA.append(val_acc)\n",
    "\n",
    "    if plot5:\n",
    "        plt.plot(VA[0])\n",
    "        plt.plot(VA[1])\n",
    "        plt.plot(VA[2])\n",
    "        plt.plot(VA[3])\n",
    "        plt.plot(VA[4])\n",
    "\n",
    "    sum = 0\n",
    "    max = 0\n",
    "    min = 1\n",
    "    for i in range(n):\n",
    "        sum += VA[i][-1] \n",
    "        if VA[i][-1] > max:\n",
    "            max = VA[i][-1]\n",
    "        if VA[i][-1] < min:\n",
    "            min = VA[i][-1]\n",
    "    \n",
    "    return (VA,sum/n,max,min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average  |  Maximum  |  Minimum  |  p1  |  p2\n",
      "0.6567567586898804 0.7027027010917664 0.5675675868988037 0 0\n",
      "New Max Avg!\n",
      "0.6945945918560028 0.7837837934494019 0.5945945978164673 0 0.1\n",
      "New Max Avg!\n",
      "0.6837837815284729 0.7297297120094299 0.5675675868988037 0 0.2\n",
      "0.7027027010917664 0.8108108043670654 0.6216216087341309 0 0.3\n",
      "New Max Avg!\n",
      "0.6756756722927093 0.7837837934494019 0.5405405163764954 0 0.4\n",
      "0.6432432472705841 0.6756756901741028 0.5945945978164673 0 0.5\n",
      "0.6783783733844757 0.7297297120094299 0.5675675868988037 0 0.6\n",
      "0.762162160873413 0.8108108043670654 0.6756756901741028 0.1 0\n",
      "New Max Avg!\n",
      "0.7702702820301056 0.837837815284729 0.6756756901741028 0.1 0.1\n",
      "New Max Avg!\n",
      "0.7567567646503448 0.8108108043670654 0.7027027010917664 0.1 0.2\n",
      "0.7405405461788177 0.8108108043670654 0.7027027010917664 0.1 0.3\n",
      "0.7297297239303588 0.8108108043670654 0.6756756901741028 0.1 0.4\n",
      "0.7486486494541168 0.8108108043670654 0.6216216087341309 0.1 0.5\n",
      "0.7378378450870514 0.7837837934494019 0.6756756901741028 0.1 0.6\n",
      "0.754054069519043 0.7837837934494019 0.7297297120094299 0.2 0\n",
      "0.7648648679256439 0.8108108043670654 0.7297297120094299 0.2 0.1\n",
      "0.7513513684272766 0.8108108043670654 0.6756756901741028 0.2 0.2\n",
      "0.7513513505458832 0.8108108043670654 0.7027027010917664 0.2 0.3\n",
      "0.7594594717025757 0.8108108043670654 0.7027027010917664 0.2 0.4\n",
      "0.7567567706108094 0.8108108043670654 0.6756756901741028 0.2 0.5\n",
      "0.6837837785482407 0.8108108043670654 0.2702702581882477 0.2 0.6\n",
      "0.745945954322815 0.7837837934494019 0.6756756901741028 0.3 0\n",
      "0.7756756901741028 0.8108108043670654 0.7567567825317383 0.3 0.1\n",
      "New Max Avg!\n",
      "0.7594594657421112 0.7837837934494019 0.7027027010917664 0.3 0.2\n",
      "0.7594594597816468 0.8108108043670654 0.6756756901741028 0.3 0.3\n",
      "0.7594594717025757 0.837837815284729 0.7027027010917664 0.3 0.4\n",
      "0.7513513445854187 0.8108108043670654 0.7027027010917664 0.3 0.5\n",
      "0.7297297418117523 0.7837837934494019 0.6756756901741028 0.3 0.6\n",
      "0.7702702760696412 0.8108108043670654 0.7027027010917664 0.4 0\n",
      "0.7567567646503448 0.7837837934494019 0.7027027010917664 0.4 0.1\n",
      "0.7378378450870514 0.7837837934494019 0.6756756901741028 0.4 0.2\n",
      "0.7567567646503448 0.837837815284729 0.6486486196517944 0.4 0.3\n",
      "0.7594594657421112 0.8108108043670654 0.7027027010917664 0.4 0.4\n",
      "0.7540540575981141 0.7837837934494019 0.7297297120094299 0.4 0.5\n",
      "0.7513513445854187 0.837837815284729 0.7027027010917664 0.4 0.6\n",
      "0.7648648738861084 0.8108108043670654 0.7297297120094299 0.5 0\n",
      "0.7486486494541168 0.8108108043670654 0.7027027010917664 0.5 0.1\n",
      "0.7405405402183532 0.8108108043670654 0.7027027010917664 0.5 0.2\n",
      "0.7729729771614074 0.8108108043670654 0.7027027010917664 0.5 0.3\n",
      "0.7729729771614074 0.8108108043670654 0.7027027010917664 0.5 0.4\n",
      "0.7513513624668121 0.7837837934494019 0.6756756901741028 0.5 0.5\n",
      "0.783783781528473 0.8108108043670654 0.7027027010917664 0.5 0.6\n",
      "New Max Avg!\n",
      "0.7567567586898803 0.837837815284729 0.6756756901741028 0.6 0\n",
      "0.7405405521392823 0.8108108043670654 0.6756756901741028 0.6 0.1\n",
      "0.7756756782531739 0.837837815284729 0.7297297120094299 0.6 0.2\n",
      "0.7837837874889374 0.837837815284729 0.7027027010917664 0.6 0.3\n",
      "New Max Avg!\n",
      "0.7567567586898803 0.8108108043670654 0.7027027010917664 0.6 0.4\n",
      "0.7756756722927094 0.8108108043670654 0.7027027010917664 0.6 0.5\n",
      "0.7567567586898803 0.8108108043670654 0.7027027010917664 0.6 0.6\n",
      "Maximum of Average accuracy at end of 500 epochs= 0.7837837874889374 at p1= 0.6, p2= 0.3\n",
      "Maximum of Max accuracy at end of 500 epochs= 0.837837815284729\n",
      "Minimum of Min accuracy at end of 500 epochs= 0.2702702581882477\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# p1 = 0.4\n",
    "# p2 = 0.4\n",
    "epochs = 500\n",
    "n = 10\n",
    "\n",
    "p_test = [0,0.1,0.2,0.3,0.4,0.5,0.6]\n",
    "\n",
    "maxmax = 0\n",
    "minmin = 1\n",
    "maxavg = 0\n",
    "best_p1 = 0\n",
    "best_p2 = 0\n",
    "print(\"Average  |  Maximum  |  Minimum  |  p1  |  p2\")\n",
    "for p1 in p_test:\n",
    "    for p2 in p_test:\n",
    "        _,avg,max,min = test_loop(p1,p2,epochs,n,plot5=False)\n",
    "        print(avg,max,min,p1,p2)\n",
    "\n",
    "        if avg > maxavg:\n",
    "            maxavg = avg\n",
    "            best_p1 = p1\n",
    "            best_p2 = p2\n",
    "            print(\"New Max Avg!\")\n",
    "        if max > maxmax:\n",
    "            maxmax = max\n",
    "        if min < minmin:\n",
    "            minmin = min\n",
    "\n",
    "\n",
    "print(f\"Maximum of Average accuracy at end of 500 epochs= {maxavg} at p1= {best_p1}, p2= {best_p2}\")\n",
    "print(f\"Maximum of Max accuracy at end of 500 epochs= {maxmax}\")\n",
    "print(f\"Minimum of Min accuracy at end of 500 epochs= {minmin}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above loop, p1 = 0.6 and p2 = 0.3 gives the best average accuracy of $\\approx 78.4$%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = get_model()\n",
    "# best_model.parameters() = best_params\n",
    "\n",
    "# best_model.eval()\n",
    "# with torch.no_grad():\n",
    "# \ttot_loss,tot_acc,count = 0.,0.,0\n",
    "# \tfor xb,yb in valid_dl:\n",
    "# \t\tpred = best_model(xb)\n",
    "# \t\tn = len(xb)\n",
    "# \t\tcount += n\n",
    "# \t\ttot_loss += loss_func(pred,yb).item()*n\n",
    "# \t\ttot_acc  += accuracy (pred,yb).item()*n\n",
    "\n",
    "# acc = tot_acc/count\n",
    "# print(acc)\n",
    "# print(best_acc)\n",
    "# print(vah[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
